{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import  StandardScaler as scaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.1, max_iters=500):\n",
    "        self.lr = lr\n",
    "        self.max_iters = max_iters\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        b = np.ones(n_samples).reshape(-1,1)\n",
    "        X = np.concatenate((b,X), axis = 1)\n",
    "\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "\n",
    "        for _ in range(self.max_iters):\n",
    "            y_hat = self.sigmoid(np.dot(X,self.weights))\n",
    "\n",
    "\n",
    "            dw = np.dot(X.T, y-y_hat)\n",
    "            self.weights+=1/n_samples*dw    \n",
    "\n",
    "        return\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(x) for x in X]) >=0.5\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        return self.sigmoid(np.dot(x, self.weights[1:])+self.weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Code Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader():\n",
    "\n",
    "    df = pd.read_csv('../data/cancer_detection.csv')\n",
    "    df.drop(columns=df.columns[[0, -1]], inplace=True)   #  Dropping non-informative columns\n",
    "    df['diagnosis'] = df['diagnosis'].map({'M':1, 'B':0})   # Malignant -> 1, Benign -> -1\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocessor(df):\n",
    "    y = df['diagnosis'].to_numpy()\n",
    "    X = df.drop(['diagnosis'], axis=1).to_numpy()\n",
    "\n",
    "    X = scaler().fit_transform(X)\n",
    "    X, y = shuffle(X,y, random_state=42)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shape: (569, 30)\n",
      "Target Shape: (569,)\n",
      "Number of examples in training set: 426\n",
      "Number of examples in test set: 143\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "X, y = preprocessor(dataloader())\n",
    "\n",
    "print(\"Feature Shape:\", X.shape)\n",
    "print(\"Target Shape:\", y.shape)\n",
    "\n",
    "train_X, test_X, train_y , test_y = tts(X, y, random_state=42)\n",
    "\n",
    "print(\"Number of examples in training set:\", train_X.shape[0])\n",
    "print(\"Number of examples in test set:\", test_X.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       268\n",
      "           1       0.99      0.97      0.98       158\n",
      "\n",
      "    accuracy                           0.98       426\n",
      "   macro avg       0.98      0.98      0.98       426\n",
      "weighted avg       0.98      0.98      0.98       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls = LogisticRegression(lr = 0.001, max_iters=50)\n",
    "cls.fit(train_X, train_y)\n",
    "\n",
    "# Perfomance on training set\n",
    "\n",
    "train_pred = cls.predict(train_X)\n",
    "\n",
    "print(classification_report(train_y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        89\n",
      "           1       1.00      0.94      0.97        54\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.97      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performance on test set\n",
    "test_pred = cls.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
